"""ç§‘ç ”åŠ©æ‰‹ä¸»å…¥å£"""
import sys
from pathlib import Path
from typing import Optional, Callable

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
src_dir = Path(__file__).parent
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

from tools.search import UnifiedSearch
from tools.query_analyzer import QueryAnalyzer
from tools.abstract_summarizer import AbstractSummarizer
from tools.reading_guide import ReadingGuide
from agents.deep_research import DeepResearchOrchestrator
from utils.config import config


class ResearchAssistant:
    """ç§‘ç ”åŠ©æ‰‹ä¸»ç±»"""

    def __init__(
        self,
        semantic_scholar_key: Optional[str] = None,
        progress_callback: Optional[Callable[[str, float], None]] = None
    ):
        """
        åˆå§‹åŒ–ç§‘ç ”åŠ©æ‰‹

        Args:
            semantic_scholar_key: Semantic Scholar API Keyï¼ˆå¯é€‰ï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œç”¨äº UI æ˜¾ç¤ºè¿›åº¦
        """
        # ä½¿ç”¨ç»Ÿä¸€æœç´¢å™¨ï¼ˆæ•´åˆarXiv + OpenAlexï¼‰
        ss_key = semantic_scholar_key or config.SEMANTIC_SCHOLAR_API_KEY
        self.searcher = UnifiedSearch(semantic_scholar_key=ss_key)
        self.progress_callback = progress_callback

        # åˆå§‹åŒ–æŸ¥è¯¢åˆ†æå™¨å’Œæ‘˜è¦æ€»ç»“å™¨
        translator_config = config.get_translator_config()
        self.deepseek_key = translator_config.get("deepseek_api_key")

        if self.deepseek_key:
            self.analyzer = QueryAnalyzer(deepseek_api_key=self.deepseek_key)
            self.summarizer = AbstractSummarizer(deepseek_api_key=self.deepseek_key)
            self.reading_guide = ReadingGuide(deepseek_api_key=self.deepseek_key)
            # æ·±åº¦ç ”ç©¶åè°ƒå™¨
            self.deep_research = DeepResearchOrchestrator(
                deepseek_api_key=self.deepseek_key,
                progress_callback=progress_callback
            )
        else:
            self.analyzer = QueryAnalyzer()  # ä¼šä½¿ç”¨å›é€€æ–¹æ¡ˆ
            self.summarizer = None
            self.reading_guide = ReadingGuide()  # ä½¿ç”¨å›é€€æ–¹æ¡ˆ
            self.deep_research = DeepResearchOrchestrator()  # ä½¿ç”¨å›é€€æ–¹æ¡ˆ
            print("æç¤º: æœªé…ç½® DEEPSEEK_API_KEYï¼Œå°†ä½¿ç”¨ç®€å•æ¨¡å¼")

    def process_query(self, query: str, mode: str = "auto", use_fulltext: bool = False) -> dict:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            mode: æœç´¢æ¨¡å¼ "auto" | "simple" | "deep_research"
                  auto: ç”± QueryAnalyzer å»ºè®®
                  simple: å¿«é€Ÿæœç´¢
                  deep_research: æ·±åº¦ç ”ç©¶
            use_fulltext: æ˜¯å¦ä½¿ç”¨å…¨æ–‡ç ”ç©¶ï¼ˆä»…æ·±åº¦ç ”ç©¶æ¨¡å¼æœ‰æ•ˆï¼Œv0.4.0ï¼‰

        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        # 1. åˆ†ææŸ¥è¯¢ï¼Œç”Ÿæˆå¤šç»„å…³é”®è¯
        analysis = self.analyzer.analyze(query)

        # 2. ç¡®å®šæ¨¡å¼
        if mode == "auto":
            mode = analysis.suggested_mode

        # 3. æ ¹æ®æ¨¡å¼æ‰§è¡Œ
        if mode == "simple":
            return self._handle_simple_query(query, analysis)
        else:
            return self._handle_deep_research(query, analysis, use_fulltext=use_fulltext)

    def _handle_simple_query(self, original_query: str, analysis) -> dict:
        """å¤„ç†å¿«é€Ÿæœç´¢"""
        # ä½¿ç”¨å¤šå…³é”®è¯æœç´¢
        result = self.searcher.search_multi_keywords(
            keywords=analysis.keywords,
            limit_per_keyword=3,
            total_limit=5
        )

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ŒæŒ‰æ¥æºåˆ†ç»„
        arxiv_papers = []
        openalex_papers = []
        for p in result.papers:
            paper_dict = {
                "title": p.title,
                "authors": p.authors[:3],
                "year": p.year,
                "citation_count": p.citation_count,
                "abstract": p.abstract,
                "url": p.url,
                "source": p.source,
            }
            if p.source == "arxiv":
                arxiv_papers.append(paper_dict)
            else:
                openalex_papers.append(paper_dict)

        all_papers = arxiv_papers + openalex_papers

        # LLMæ€»ç»“æ‘˜è¦ï¼ˆæ‰¹é‡å¹¶è¡Œå¤„ç†ï¼‰
        if self.summarizer and all_papers:
            all_papers = self.summarizer.summarize_batch(all_papers)
            arxiv_papers = [p for p in all_papers if p.get('source') == 'arxiv']
            openalex_papers = [p for p in all_papers if p.get('source') == 'openalex']

        # ç”Ÿæˆé˜…è¯»å¯¼èˆª
        reading_guide = self.reading_guide.generate(original_query, all_papers)

        return {
            "mode": "simple",
            "query": original_query,
            "intent": analysis.intent,
            "keywords": analysis.keywords,
            "suggested_mode": analysis.suggested_mode,
            "sources": result.sources_used,
            "total_found": result.total_count,
            "arxiv_papers": arxiv_papers,
            "openalex_papers": openalex_papers,
            "papers": all_papers,
            "reading_guide": reading_guide,
        }

    def _handle_deep_research(self, original_query: str, analysis, use_fulltext: bool = False) -> dict:
        """
        å¤„ç†æ·±åº¦ç ”ç©¶æŸ¥è¯¢

        v0.3.0 å®ç°ï¼š
        - å­é—®é¢˜åˆ†è§£
        - å¹¶è¡Œæœç´¢ç ”ç©¶
        - ç»¼åˆåˆ†ææŠ¥å‘Š

        v0.4.0 æ–°å¢ï¼š
        - æ”¯æŒå…¨æ–‡ç ”ç©¶æ¨¡å¼ï¼ˆä¸‹è½½ PDFï¼‰
        """
        # æ ¹æ® use_fulltext åˆ›å»ºé…ç½®
        from agents.deep_research import DeepResearchConfig
        config = DeepResearchConfig(use_fulltext=use_fulltext)

        # åˆ›å»ºåè°ƒå™¨å®ä¾‹ï¼ˆä½¿ç”¨æŒ‡å®šé…ç½®ï¼‰
        orchestrator = DeepResearchOrchestrator(
            deepseek_api_key=self.deepseek_key,
            config=config,
            progress_callback=self.progress_callback
        )

        # æ‰§è¡Œæ·±åº¦ç ”ç©¶
        deep_result = orchestrator.run(original_query)

        # æ”¶é›†æ‰€æœ‰è®ºæ–‡ï¼ˆä»å„å­é—®é¢˜çš„ç ”ç©¶ç»“æœä¸­æå–ï¼‰
        all_papers = []
        arxiv_papers = []
        openalex_papers = []

        seen_titles = set()  # å»é‡
        for research_result in deep_result.research_results:
            for src in research_result.sources:
                title = src.get("title", "")
                if title.lower() in seen_titles:
                    continue
                seen_titles.add(title.lower())

                paper_dict = {
                    "title": title,
                    "authors": src.get("authors", []),
                    "year": src.get("year"),
                    "citation_count": src.get("citation_count"),
                    "abstract": src.get("abstract", ""),
                    "url": src.get("url", ""),
                    "source": src.get("source", "unknown"),
                    "relevance": src.get("relevance", ""),
                }
                all_papers.append(paper_dict)

                if src.get("source") == "arxiv":
                    arxiv_papers.append(paper_dict)
                else:
                    openalex_papers.append(paper_dict)

        # æ·±åº¦ç ”ç©¶æ¨¡å¼ä¸éœ€è¦é¢å¤–çš„æ‘˜è¦æ€»ç»“ï¼ŒæŠ¥å‘Šå·²åŒ…å«åˆ†æ
        # åªæˆªå–åŸå§‹æ‘˜è¦çš„å‰150å­—ä½œä¸ºç®€è¦è¯´æ˜
        for paper in all_papers:
            abstract = paper.get("abstract", "")
            if abstract and len(abstract) > 150:
                paper["summary"] = abstract[:150] + "..."
            elif abstract:
                paper["summary"] = abstract

        # ç”Ÿæˆé˜…è¯»å¯¼èˆªï¼ˆåŸºäºæŠ¥å‘Šä¸­çš„è®ºæ–‡ï¼‰
        reading_guide = self.reading_guide.generate(original_query, all_papers)

        # è·å–æŠ¥å‘Šä¸­çš„å‚è€ƒæ¥æºï¼ˆä¸æŠ¥å‘Šå¼•ç”¨ç¼–å·ä¸€è‡´ï¼‰
        report_sources = []
        if deep_result.report and deep_result.report.sources:
            for src in deep_result.report.sources:
                report_sources.append({
                    "title": src.get("title", ""),
                    "authors": src.get("authors", []),
                    "year": src.get("year"),
                    "citation_count": src.get("citation_count"),
                    "abstract": src.get("abstract", ""),
                    "url": src.get("url", ""),
                    "source": src.get("source", "unknown"),
                    "relevance": src.get("relevance", ""),
                    "summary": src.get("abstract", "")[:150] + "..." if src.get("abstract", "") and len(src.get("abstract", "")) > 150 else src.get("abstract", ""),
                })

        return {
            "mode": "deep_research",
            "query": original_query,
            "intent": analysis.intent,
            "keywords": analysis.keywords,
            "sources": ["arxiv", "openalex"],
            "total_found": deep_result.metadata.get("total_papers", 0),
            "arxiv_papers": arxiv_papers,
            "openalex_papers": openalex_papers,
            "papers": all_papers,
            "reading_guide": reading_guide,
            # æ·±åº¦ç ”ç©¶ç‰¹æœ‰å†…å®¹
            "report": deep_result.report_markdown,
            "report_sources": report_sources,  # ä¸æŠ¥å‘Šå¼•ç”¨ç¼–å·ä¸€è‡´çš„å‚è€ƒæ¥æº
            "decomposition": {
                "query_type": deep_result.decomposition.query_type,
                "strategy": deep_result.decomposition.research_strategy,
                "sub_questions": [
                    {
                        "question": sq.question,
                        "purpose": sq.purpose,
                        "keywords": sq.search_keywords
                    }
                    for sq in deep_result.decomposition.sub_questions
                ]
            },
            "metadata": deep_result.metadata,
        }


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    print("=" * 50)
    print("ç§‘ç ”åŠ©æ‰‹ v0.3.0")
    print("æ”¯æŒæ·±åº¦ç ”ç©¶ï¼šå­é—®é¢˜åˆ†è§£ + å¹¶è¡Œæœç´¢ + ç ”ç©¶æŠ¥å‘Š")
    print("=" * 50)

    assistant = ResearchAssistant()

    while True:
        try:
            query = input("\nè¯·è¾“å…¥ç ”ç©¶é—®é¢˜ (è¾“å…¥ 'quit' é€€å‡º): ").strip()

            if query.lower() in ["quit", "exit", "q"]:
                print("å†è§ï¼")
                break

            if not query:
                continue

            print(f"\næ­£åœ¨åˆ†æ: {query}")
            print("ï¼ˆä½¿ç”¨ arXiv + OpenAlex å¤šå…³é”®è¯å¹¶è¡Œæœç´¢ï¼‰\n")

            result = assistant.process_query(query)

            print(f"æ„å›¾: {result.get('intent', '')}")
            print(f"å…³é”®è¯: {result.get('keywords', [])}")
            print(f"æ¨¡å¼: {result['mode']}")
            print(f"æœç´¢æº: {', '.join(result.get('sources', []))}")

            # æ·±åº¦ç ”ç©¶æ¨¡å¼æ˜¾ç¤ºæŠ¥å‘Š
            if result['mode'] == 'deep_research' and result.get('report'):
                print("\n" + "=" * 50)
                print("æ·±åº¦ç ”ç©¶æŠ¥å‘Š")
                print("=" * 50)
                print(result['report'])
            else:
                # å¿«é€Ÿæœç´¢æ¨¡å¼æ˜¾ç¤ºè®ºæ–‡åˆ—è¡¨
                print(f"æ‰¾åˆ° {len(result['papers'])} ç¯‡ç›¸å…³è®ºæ–‡:\n")

                for i, paper in enumerate(result["papers"], 1):
                    source_tag = f"[{paper.get('source', 'unknown')}]"
                    print(f"[{i}] {source_tag} {paper['title']}")
                    if paper.get('title_cn'):
                        print(f"    ğŸ“– {paper['title_cn']}")
                    authors = paper.get('authors', [])
                    if authors:
                        print(f"    ä½œè€…: {', '.join(authors)}")
                    print(f"    å¹´ä»½: {paper.get('year', 'N/A')}")
                    if paper.get('citation_count'):
                        print(f"    å¼•ç”¨: {paper['citation_count']}")
                    if paper.get('summary'):
                        print(f"    æ‘˜è¦: {paper['summary']}")
                    print(f"    é“¾æ¥: {paper['url']}")
                    print()

        except KeyboardInterrupt:
            print("\nå†è§ï¼")
            break
        except Exception as e:
            print(f"å¤„ç†å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()
