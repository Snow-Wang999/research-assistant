"""ç§‘ç ”åŠ©æ‰‹ä¸»å…¥å£"""
import sys
from pathlib import Path
from typing import Optional

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
src_dir = Path(__file__).parent
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

from tools.search import UnifiedSearch
from tools.query_analyzer import QueryAnalyzer
from tools.abstract_summarizer import AbstractSummarizer
from tools.reading_guide import ReadingGuide
from utils.config import config


class ResearchAssistant:
    """ç§‘ç ”åŠ©æ‰‹ä¸»ç±»"""

    def __init__(self, semantic_scholar_key: Optional[str] = None):
        # ä½¿ç”¨ç»Ÿä¸€æœç´¢å™¨ï¼ˆæ•´åˆarXiv + OpenAlexï¼‰
        ss_key = semantic_scholar_key or config.SEMANTIC_SCHOLAR_API_KEY
        self.searcher = UnifiedSearch(semantic_scholar_key=ss_key)

        # åˆå§‹åŒ–æŸ¥è¯¢åˆ†æå™¨å’Œæ‘˜è¦æ€»ç»“å™¨
        translator_config = config.get_translator_config()
        deepseek_key = translator_config.get("deepseek_api_key")

        if deepseek_key:
            self.analyzer = QueryAnalyzer(deepseek_api_key=deepseek_key)
            self.summarizer = AbstractSummarizer(deepseek_api_key=deepseek_key)
            self.reading_guide = ReadingGuide(deepseek_api_key=deepseek_key)
        else:
            self.analyzer = QueryAnalyzer()  # ä¼šä½¿ç”¨å›é€€æ–¹æ¡ˆ
            self.summarizer = None
            self.reading_guide = ReadingGuide()  # ä½¿ç”¨å›é€€æ–¹æ¡ˆ
            print("æç¤º: æœªé…ç½® DEEPSEEK_API_KEYï¼Œå°†ä½¿ç”¨ç®€å•æ¨¡å¼")

    def process_query(self, query: str, mode: str = "auto") -> dict:
        """
        å¤„ç†ç”¨æˆ·æŸ¥è¯¢

        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            mode: æœç´¢æ¨¡å¼ "auto" | "simple" | "deep_research"
                  auto: ç”± QueryAnalyzer å»ºè®®
                  simple: å¿«é€Ÿæœç´¢
                  deep_research: æ·±åº¦ç ”ç©¶ï¼ˆæš‚æœªå®ç°å®Œæ•´åŠŸèƒ½ï¼‰

        Returns:
            æœç´¢ç»“æœå­—å…¸
        """
        # 1. åˆ†ææŸ¥è¯¢ï¼Œç”Ÿæˆå¤šç»„å…³é”®è¯
        analysis = self.analyzer.analyze(query)

        # 2. ç¡®å®šæ¨¡å¼
        if mode == "auto":
            mode = analysis.suggested_mode

        # 3. æ ¹æ®æ¨¡å¼æ‰§è¡Œ
        if mode == "simple":
            return self._handle_simple_query(query, analysis)
        else:
            return self._handle_deep_research(query, analysis)

    def _handle_simple_query(self, original_query: str, analysis) -> dict:
        """å¤„ç†å¿«é€Ÿæœç´¢"""
        # ä½¿ç”¨å¤šå…³é”®è¯æœç´¢
        result = self.searcher.search_multi_keywords(
            keywords=analysis.keywords,
            limit_per_keyword=3,
            total_limit=5
        )

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ŒæŒ‰æ¥æºåˆ†ç»„
        arxiv_papers = []
        openalex_papers = []
        for p in result.papers:
            paper_dict = {
                "title": p.title,
                "authors": p.authors[:3],
                "year": p.year,
                "citation_count": p.citation_count,
                "abstract": p.abstract,
                "url": p.url,
                "source": p.source,
            }
            if p.source == "arxiv":
                arxiv_papers.append(paper_dict)
            else:
                openalex_papers.append(paper_dict)

        all_papers = arxiv_papers + openalex_papers

        # LLMæ€»ç»“æ‘˜è¦ï¼ˆæ‰¹é‡å¹¶è¡Œå¤„ç†ï¼‰
        if self.summarizer and all_papers:
            all_papers = self.summarizer.summarize_batch(all_papers)
            arxiv_papers = [p for p in all_papers if p.get('source') == 'arxiv']
            openalex_papers = [p for p in all_papers if p.get('source') == 'openalex']

        # ç”Ÿæˆé˜…è¯»å¯¼èˆª
        reading_guide = self.reading_guide.generate(original_query, all_papers)

        return {
            "mode": "simple",
            "query": original_query,
            "intent": analysis.intent,
            "keywords": analysis.keywords,
            "suggested_mode": analysis.suggested_mode,
            "sources": result.sources_used,
            "total_found": result.total_count,
            "arxiv_papers": arxiv_papers,
            "openalex_papers": openalex_papers,
            "papers": all_papers,
            "reading_guide": reading_guide,
        }

    def _handle_deep_research(self, original_query: str, analysis) -> dict:
        """
        å¤„ç†æ·±åº¦ç ”ç©¶æŸ¥è¯¢

        TODO: v0.3.0 å®ç°å®Œæ•´çš„æ·±åº¦ç ”ç©¶åŠŸèƒ½
        - å­é—®é¢˜åˆ†è§£
        - å¤šè½®è¿­ä»£æœç´¢
        - ç»¼åˆåˆ†ææŠ¥å‘Š
        """
        # å½“å‰ï¼šä½¿ç”¨æ›´å¤šçš„æœç´¢ç»“æœ
        result = self.searcher.search_multi_keywords(
            keywords=analysis.keywords,
            limit_per_keyword=5,
            total_limit=10  # Deep Research è¿”å›æ›´å¤šç»“æœ
        )

        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        arxiv_papers = []
        openalex_papers = []
        for p in result.papers:
            paper_dict = {
                "title": p.title,
                "authors": p.authors[:3],
                "year": p.year,
                "citation_count": p.citation_count,
                "abstract": p.abstract,
                "url": p.url,
                "source": p.source,
            }
            if p.source == "arxiv":
                arxiv_papers.append(paper_dict)
            else:
                openalex_papers.append(paper_dict)

        all_papers = arxiv_papers + openalex_papers

        # LLMæ€»ç»“æ‘˜è¦
        if self.summarizer and all_papers:
            all_papers = self.summarizer.summarize_batch(all_papers)
            arxiv_papers = [p for p in all_papers if p.get('source') == 'arxiv']
            openalex_papers = [p for p in all_papers if p.get('source') == 'openalex']

        # ç”Ÿæˆé˜…è¯»å¯¼èˆª
        reading_guide = self.reading_guide.generate(original_query, all_papers)

        return {
            "mode": "deep_research",
            "query": original_query,
            "intent": analysis.intent,
            "keywords": analysis.keywords,
            "sources": result.sources_used,
            "total_found": result.total_count,
            "arxiv_papers": arxiv_papers,
            "openalex_papers": openalex_papers,
            "papers": all_papers,
            "reading_guide": reading_guide,
            # TODO: æ·»åŠ æ·±åº¦åˆ†ææŠ¥å‘Š
            "report": None,
        }


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    print("=" * 50)
    print("ç§‘ç ”åŠ©æ‰‹ v0.2.0")
    print("=" * 50)

    assistant = ResearchAssistant()

    while True:
        try:
            query = input("\nè¯·è¾“å…¥ç ”ç©¶é—®é¢˜ (è¾“å…¥ 'quit' é€€å‡º): ").strip()

            if query.lower() in ["quit", "exit", "q"]:
                print("å†è§ï¼")
                break

            if not query:
                continue

            print(f"\næ­£åœ¨åˆ†æ: {query}")
            print("ï¼ˆä½¿ç”¨ arXiv + OpenAlex å¤šå…³é”®è¯å¹¶è¡Œæœç´¢ï¼‰\n")

            result = assistant.process_query(query)

            print(f"æ„å›¾: {result.get('intent', '')}")
            print(f"å…³é”®è¯: {result.get('keywords', [])}")
            print(f"æ¨¡å¼: {result['mode']}")
            print(f"æœç´¢æº: {', '.join(result.get('sources', []))}")
            print(f"æ‰¾åˆ° {len(result['papers'])} ç¯‡ç›¸å…³è®ºæ–‡:\n")

            for i, paper in enumerate(result["papers"], 1):
                source_tag = f"[{paper.get('source', 'unknown')}]"
                print(f"[{i}] {source_tag} {paper['title']}")
                if paper.get('title_cn'):
                    print(f"    ğŸ“– {paper['title_cn']}")
                print(f"    ä½œè€…: {', '.join(paper['authors'])}")
                print(f"    å¹´ä»½: {paper.get('year', 'N/A')}")
                if paper.get('citation_count'):
                    print(f"    å¼•ç”¨: {paper['citation_count']}")
                if paper.get('summary'):
                    print(f"    æ‘˜è¦: {paper['summary']}")
                print(f"    é“¾æ¥: {paper['url']}")
                print()

        except KeyboardInterrupt:
            print("\nå†è§ï¼")
            break
        except Exception as e:
            print(f"å¤„ç†å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()
