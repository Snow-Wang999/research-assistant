"""è®ºæ–‡ç­›é€‰å™¨

åŸºäºæ‘˜è¦ç­›é€‰ç›¸å…³è®ºæ–‡ï¼Œå†³å®šå“ªäº›è®ºæ–‡å€¼å¾—è·å–å…¨æ–‡ã€‚
å‚è€ƒ Elicit çš„ Screening æµç¨‹è®¾è®¡ã€‚
"""

import json
import re
from typing import List, Optional
from dataclasses import dataclass, field

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.llm_client import QwenClient


@dataclass
class ScreenedPaper:
    """ç­›é€‰åçš„è®ºæ–‡"""
    paper_id: str
    title: str
    authors: List[str]
    year: Optional[int]
    abstract: str
    url: str
    source: str
    citation_count: Optional[int]
    # ç­›é€‰ç»“æœ
    relevance_score: int  # 1-5 åˆ†
    relevance_reason: str  # ç›¸å…³åŸå› 
    should_get_fulltext: bool  # æ˜¯å¦éœ€è¦è·å–å…¨æ–‡

    @property
    def arxiv_id(self) -> Optional[str]:
        """æå– arXiv IDï¼ˆå¦‚æœæ˜¯ arXiv è®ºæ–‡ï¼‰"""
        if self.source == "arxiv":
            # ä» URL æˆ– paper_id æå–
            match = re.search(r'(\d{4}\.\d{4,5})', self.url or self.paper_id)
            if match:
                return match.group(1)
        return None


@dataclass
class ScreeningResult:
    """ç­›é€‰ç»“æœ"""
    query: str
    total_papers: int
    screened_papers: List[ScreenedPaper]
    papers_for_fulltext: List[ScreenedPaper]  # éœ€è¦è·å–å…¨æ–‡çš„è®ºæ–‡

    @property
    def fulltext_count(self) -> int:
        return len(self.papers_for_fulltext)


class PaperScreener:
    """
    è®ºæ–‡ç­›é€‰å™¨

    ä½¿ç”¨ LLM åŸºäºæ‘˜è¦ç­›é€‰ç›¸å…³è®ºæ–‡ï¼Œå†³å®šå“ªäº›å€¼å¾—è·å–å…¨æ–‡ã€‚
    """

    SCREENING_PROMPT = """ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯è®ºæ–‡ç­›é€‰ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯è¯„ä¼°æ¯ç¯‡è®ºæ–‡ä¸ç ”ç©¶é—®é¢˜çš„ç›¸å…³æ€§ã€‚

ç ”ç©¶é—®é¢˜: {query}

è¯·è¯„ä¼°ä»¥ä¸‹è®ºæ–‡çš„ç›¸å…³æ€§ã€‚å¯¹äºæ¯ç¯‡è®ºæ–‡ï¼Œè¯·åˆ¤æ–­ï¼š
1. ç›¸å…³æ€§è¯„åˆ† (1-5åˆ†)
2. æ˜¯å¦éœ€è¦è·å–å…¨æ–‡è¿›è¡Œæ·±å…¥åˆ†æ

è¯„åˆ†æ ‡å‡†ï¼š
- 5åˆ†ï¼šæ ¸å¿ƒç›¸å…³ï¼Œç›´æ¥è®¨è®ºç ”ç©¶é—®é¢˜ï¼Œå¿…é¡»è·å–å…¨æ–‡
- 4åˆ†ï¼šé«˜åº¦ç›¸å…³ï¼Œæä¾›é‡è¦è¯æ®æˆ–æ–¹æ³•ï¼Œåº”è¯¥è·å–å…¨æ–‡
- 3åˆ†ï¼šä¸­ç­‰ç›¸å…³ï¼Œæä¾›èƒŒæ™¯æˆ–éƒ¨åˆ†ç›¸å…³ä¿¡æ¯ï¼Œå¯é€‰è·å–å…¨æ–‡
- 2åˆ†ï¼šä½ç›¸å…³ï¼Œä»…é—´æ¥æ¶‰åŠï¼Œä¸éœ€è¦å…¨æ–‡
- 1åˆ†ï¼šä¸ç›¸å…³ï¼Œè·³è¿‡

è®ºæ–‡åˆ—è¡¨ï¼š
{papers_text}

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºè¯„ä¼°ç»“æœï¼š
{{
  "evaluations": [
    {{
      "index": 1,
      "score": 5,
      "reason": "ç›´æ¥å¯¹æ¯”äº† Transformer å’Œ RNN çš„æ€§èƒ½",
      "need_fulltext": true
    }},
    {{
      "index": 2,
      "score": 2,
      "reason": "ä»…æåˆ° Transformerï¼Œä½†ä¸»é¢˜æ˜¯å›¾åƒåˆ†ç±»",
      "need_fulltext": false
    }}
  ]
}}

è¦æ±‚ï¼š
1. ä¸¥æ ¼è¯„ä¼°ç›¸å…³æ€§ï¼Œä¸è¦æ”¾æ°´
2. åªæœ‰ score >= 4 çš„è®ºæ–‡æ‰è®¾ç½® need_fulltext: true
3. ä¼˜å…ˆé€‰æ‹©é«˜å¼•ç”¨ã€è¿‘æœŸå‘è¡¨çš„è®ºæ–‡
4. å…¨æ–‡è·å–æ•°é‡æ§åˆ¶åœ¨ {max_fulltext} ç¯‡ä»¥å†…"""

    def __init__(
        self,
        qwen_api_key: Optional[str] = None,
        max_fulltext: int = 15,
        min_score_for_fulltext: int = 4
    ):
        """
        åˆå§‹åŒ–ç­›é€‰å™¨

        Args:
            qwen_api_key: é€šä¹‰åƒé—® API Key
            max_fulltext: æœ€å¤§è·å–å…¨æ–‡çš„è®ºæ–‡æ•°
            min_score_for_fulltext: è·å–å…¨æ–‡çš„æœ€ä½åˆ†æ•°
        """
        self.llm_client = QwenClient(api_key=qwen_api_key) if qwen_api_key else None
        self.max_fulltext = max_fulltext
        self.min_score_for_fulltext = min_score_for_fulltext

    def screen(
        self,
        query: str,
        papers: List[dict],
        max_fulltext: Optional[int] = None
    ) -> ScreeningResult:
        """
        ç­›é€‰è®ºæ–‡

        Args:
            query: ç ”ç©¶é—®é¢˜
            papers: è®ºæ–‡åˆ—è¡¨ï¼ˆéœ€åŒ…å« title, abstract, authors, year ç­‰ï¼‰
            max_fulltext: æœ€å¤§è·å–å…¨æ–‡æ•°é‡ï¼ˆè¦†ç›–é»˜è®¤å€¼ï¼‰

        Returns:
            ScreeningResult: ç­›é€‰ç»“æœ
        """
        if not papers:
            return ScreeningResult(
                query=query,
                total_papers=0,
                screened_papers=[],
                papers_for_fulltext=[]
            )

        max_ft = max_fulltext or self.max_fulltext

        if self.llm_client:
            return self._screen_with_llm(query, papers, max_ft)
        else:
            return self._screen_fallback(query, papers, max_ft)

    def _format_papers_for_prompt(self, papers: List[dict]) -> str:
        """æ ¼å¼åŒ–è®ºæ–‡åˆ—è¡¨ç”¨äº prompt"""
        lines = []
        for i, p in enumerate(papers, 1):
            year = p.get('year', 'N/A')
            citations = p.get('citation_count', 0) or 0
            abstract = (p.get('abstract') or '')[:400]
            source = p.get('source', 'unknown').upper()

            lines.append(
                f"[{i}] {p.get('title', 'Untitled')}\n"
                f"    æ¥æº: {source} | å¹´ä»½: {year} | å¼•ç”¨: {citations}\n"
                f"    æ‘˜è¦: {abstract}..."
            )
        return "\n\n".join(lines)

    def _screen_with_llm(
        self,
        query: str,
        papers: List[dict],
        max_fulltext: int
    ) -> ScreeningResult:
        """ä½¿ç”¨ LLM ç­›é€‰"""
        try:
            papers_text = self._format_papers_for_prompt(papers)

            prompt = self.SCREENING_PROMPT.format(
                query=query,
                papers_text=papers_text,
                max_fulltext=max_fulltext
            )

            print(f"[PaperScreener] ç­›é€‰ {len(papers)} ç¯‡è®ºæ–‡...")

            # ä½¿ç”¨é€šä¹‰åƒé—® turbo æ¨¡å‹ï¼ˆè®ºæ–‡ç­›é€‰æ˜¯ç®€å•åˆ†ç±»ä»»åŠ¡ï¼‰
            content = self.llm_client.chat(
                prompt=prompt,
                task_type="screen",
                max_tokens=2000,
                temperature=0.2,
                timeout=30.0
            )

            evaluations = self._parse_response(content)

            if evaluations:
                return self._build_result(query, papers, evaluations, max_fulltext)

        except Exception as e:
            print(f"[PaperScreener] LLM ç­›é€‰å‡ºé”™: {type(e).__name__}: {e}")

        return self._screen_fallback(query, papers, max_fulltext)

    def _parse_response(self, content: str) -> Optional[List[dict]]:
        """è§£æ LLM å“åº”"""
        try:
            data = json.loads(content)
            return data.get("evaluations", [])
        except json.JSONDecodeError:
            pass

        # å°è¯•æå– JSON
        json_match = re.search(r'\{[\s\S]*\}', content)
        if json_match:
            try:
                data = json.loads(json_match.group())
                return data.get("evaluations", [])
            except json.JSONDecodeError:
                pass

        return None

    def _build_result(
        self,
        query: str,
        papers: List[dict],
        evaluations: List[dict],
        max_fulltext: int
    ) -> ScreeningResult:
        """æ„å»ºç­›é€‰ç»“æœ"""
        screened_papers = []

        # åˆ›å»ºè¯„ä¼°å­—å…¸ï¼ˆindex -> evaluationï¼‰
        eval_dict = {e.get("index", 0): e for e in evaluations}

        for i, paper in enumerate(papers, 1):
            eval_data = eval_dict.get(i, {})
            score = eval_data.get("score", 2)
            reason = eval_data.get("reason", "")
            need_fulltext = eval_data.get("need_fulltext", False)

            screened = ScreenedPaper(
                paper_id=paper.get("paper_id", f"paper_{i}"),
                title=paper.get("title", ""),
                authors=paper.get("authors", []),
                year=paper.get("year"),
                abstract=paper.get("abstract", ""),
                url=paper.get("url", ""),
                source=paper.get("source", "unknown"),
                citation_count=paper.get("citation_count"),
                relevance_score=score,
                relevance_reason=reason,
                should_get_fulltext=need_fulltext and score >= self.min_score_for_fulltext
            )
            screened_papers.append(screened)

        # æŒ‰åˆ†æ•°æ’åº
        screened_papers.sort(key=lambda x: (-x.relevance_score, -(x.citation_count or 0)))

        # é€‰æ‹©éœ€è¦è·å–å…¨æ–‡çš„è®ºæ–‡
        papers_for_fulltext = [
            p for p in screened_papers
            if p.should_get_fulltext
        ][:max_fulltext]

        print(f"[PaperScreener] ç­›é€‰å®Œæˆ: {len(papers_for_fulltext)}/{len(papers)} ç¯‡éœ€è¦è·å–å…¨æ–‡")

        return ScreeningResult(
            query=query,
            total_papers=len(papers),
            screened_papers=screened_papers,
            papers_for_fulltext=papers_for_fulltext
        )

    def _screen_fallback(
        self,
        query: str,
        papers: List[dict],
        max_fulltext: int
    ) -> ScreeningResult:
        """å›é€€æ–¹æ¡ˆï¼šåŸºäºå¼•ç”¨æ•°å’Œå¹´ä»½ç­›é€‰"""
        print("[PaperScreener] ä½¿ç”¨å›é€€ç­›é€‰æ–¹æ¡ˆ...")

        screened_papers = []
        query_lower = query.lower()
        query_words = set(query_lower.split())

        for i, paper in enumerate(papers):
            title_lower = (paper.get("title") or "").lower()
            abstract_lower = (paper.get("abstract") or "").lower()

            # ç®€å•ç›¸å…³æ€§è¯„åˆ†
            title_match = sum(1 for w in query_words if w in title_lower)
            abstract_match = sum(1 for w in query_words if w in abstract_lower)

            # å¼•ç”¨æ•°åŠ åˆ†
            citations = paper.get("citation_count", 0) or 0
            citation_bonus = min(2, citations // 100)

            # å¹´ä»½åŠ åˆ†ï¼ˆè¿‘3å¹´ï¼‰
            year = paper.get("year") or 2020
            year_bonus = 1 if year >= 2022 else 0

            score = min(5, 2 + title_match + (1 if abstract_match > 2 else 0) + citation_bonus + year_bonus)

            screened = ScreenedPaper(
                paper_id=paper.get("paper_id", f"paper_{i}"),
                title=paper.get("title", ""),
                authors=paper.get("authors", []),
                year=paper.get("year"),
                abstract=paper.get("abstract", ""),
                url=paper.get("url", ""),
                source=paper.get("source", "unknown"),
                citation_count=citations,
                relevance_score=score,
                relevance_reason="åŸºäºå…³é”®è¯åŒ¹é…å’Œå¼•ç”¨æ•°",
                should_get_fulltext=score >= self.min_score_for_fulltext
            )
            screened_papers.append(screened)

        # æ’åº
        screened_papers.sort(key=lambda x: (-x.relevance_score, -(x.citation_count or 0)))

        # é€‰æ‹©å…¨æ–‡
        papers_for_fulltext = [
            p for p in screened_papers
            if p.should_get_fulltext
        ][:max_fulltext]

        return ScreeningResult(
            query=query,
            total_papers=len(papers),
            screened_papers=screened_papers,
            papers_for_fulltext=papers_for_fulltext
        )


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import os
    from dotenv import load_dotenv

    load_dotenv()

    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    test_papers = [
        {
            "paper_id": "1706.03762",
            "title": "Attention Is All You Need",
            "authors": ["Vaswani", "Shazeer", "Parmar"],
            "year": 2017,
            "abstract": "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms...",
            "url": "https://arxiv.org/abs/1706.03762",
            "source": "arxiv",
            "citation_count": 98000
        },
        {
            "paper_id": "1810.04805",
            "title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
            "authors": ["Devlin", "Chang", "Lee"],
            "year": 2018,
            "abstract": "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers...",
            "url": "https://arxiv.org/abs/1810.04805",
            "source": "arxiv",
            "citation_count": 75000
        },
        {
            "paper_id": "2001.08361",
            "title": "Scaling Laws for Neural Language Models",
            "authors": ["Kaplan", "McCandlish"],
            "year": 2020,
            "abstract": "We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training...",
            "url": "https://arxiv.org/abs/2001.08361",
            "source": "arxiv",
            "citation_count": 3000
        },
        {
            "paper_id": "some_unrelated",
            "title": "A Survey on Image Classification using CNN",
            "authors": ["Smith", "Johnson"],
            "year": 2021,
            "abstract": "This paper surveys various convolutional neural network architectures for image classification tasks...",
            "url": "https://example.com/paper",
            "source": "openalex",
            "citation_count": 100
        }
    ]

    screener = PaperScreener(
        qwen_api_key=os.getenv("QWEN_API_KEY"),
        max_fulltext=10
    )

    print("=" * 60)
    print("è®ºæ–‡ç­›é€‰å™¨æµ‹è¯•")
    print("=" * 60)

    result = screener.screen(
        query="Transformer æ¶æ„çš„å‘å±•å’Œåœ¨ NLP ä¸­çš„åº”ç”¨",
        papers=test_papers
    )

    print(f"\næŸ¥è¯¢: {result.query}")
    print(f"æ€»è®ºæ–‡æ•°: {result.total_papers}")
    print(f"éœ€è¦è·å–å…¨æ–‡: {result.fulltext_count} ç¯‡")

    print("\nç­›é€‰ç»“æœ:")
    for p in result.screened_papers:
        ft_mark = "ğŸ“„" if p.should_get_fulltext else "  "
        print(f"  {ft_mark} [{p.relevance_score}åˆ†] {p.title[:50]}...")
        print(f"       åŸå› : {p.relevance_reason}")

    print("\néœ€è¦è·å–å…¨æ–‡çš„è®ºæ–‡:")
    for p in result.papers_for_fulltext:
        print(f"  - {p.title[:50]}... (arXiv: {p.arxiv_id})")
