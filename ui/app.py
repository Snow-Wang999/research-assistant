"""Gradio Webç•Œé¢ - æ”¯æŒæµå¼è¾“å‡º"""
import gradio as gr
import sys
import time
from pathlib import Path
from datetime import datetime

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
src_dir = project_root / "src"
if str(src_dir) not in sys.path:
    sys.path.insert(0, str(src_dir))

from main import ResearchAssistant
from tools.reading_guide import ReadingGuide


def create_app():
    """åˆ›å»ºGradioåº”ç”¨"""
    assistant = ResearchAssistant()

    def format_paper(paper: dict, index: int, show_source: bool = False) -> str:
        """æ ¼å¼åŒ–å•ç¯‡è®ºæ–‡"""
        title = paper.get('title', 'æœªçŸ¥æ ‡é¢˜')
        title_cn = paper.get('title_cn', '')
        source_tag = f" [{paper.get('source', '')}]" if show_source else ""

        if title_cn:
            output = f"**[{index}]{source_tag} {title}**\n\n"
            output += f"ğŸ“– *{title_cn}*\n\n"
        else:
            output = f"**[{index}]{source_tag} {title}**\n\n"

        authors = paper.get('authors', [])
        if authors:
            output += f"- ä½œè€…: {', '.join(authors[:3])}\n"
        output += f"- å¹´ä»½: {paper.get('year', 'N/A')}\n"
        if paper.get("citation_count"):
            output += f"- å¼•ç”¨: {paper['citation_count']}\n"

        summary = paper.get('summary', '')
        if summary:
            output += f"- ğŸ“ **æ‘˜è¦**: {summary}\n"
        elif paper.get("abstract"):
            abstract = paper['abstract']
            if len(abstract) > 200:
                abstract = abstract[:200] + "..."
            output += f"- æ‘˜è¦: {abstract}\n"

        if paper.get('url'):
            output += f"- [ğŸ”— æŸ¥çœ‹è®ºæ–‡]({paper['url']})\n\n"
        output += "---\n\n"
        return output

    def format_reading_guide(guide: dict) -> str:
        """æ ¼å¼åŒ–é˜…è¯»å¯¼èˆª"""
        if not guide or guide.get("error"):
            return ""

        lines = ["## ğŸ“š é˜…è¯»å»ºè®®\n"]

        if guide.get("summary"):
            lines.append(f"{guide['summary']}\n")

        if guide.get("entry_point"):
            ep = guide["entry_point"]
            title = ep.get('title', '')[:60]
            lines.append(f"### ğŸŒŸ å…¥é—¨å¿…è¯»")
            lines.append(f"**[{ep.get('index', '')}] {title}...**")
            lines.append(f"> {ep.get('reason', '')}\n")

        if guide.get("core_papers"):
            lines.append(f"### ğŸ“Œ æ ¸å¿ƒè®ºæ–‡")
            for cp in guide["core_papers"]:
                title = cp.get('title', '')[:60]
                lines.append(f"- **[{cp.get('index', '')}] {title}...** â†’ {cp.get('reason', '')}")
            lines.append("")

        if guide.get("latest"):
            lt = guide["latest"]
            title = lt.get('title', '')[:60]
            lines.append(f"### ğŸ†• æœ€æ–°è¿›å±•")
            lines.append(f"**[{lt.get('index', '')}] {title}...**")
            lines.append(f"> {lt.get('reason', '')}\n")

        if guide.get("reading_order"):
            order = guide["reading_order"][:5]
            lines.append(f"### ğŸ“– æ¨èé˜…è¯»é¡ºåº")
            lines.append(f"**{' â†’ '.join(map(str, order))}**\n")

        if guide.get("categories"):
            lines.append(f"### ğŸ“‚ è®ºæ–‡åˆ†ç±»\n")
            for cat in guide["categories"]:
                name = cat.get("name", "å…¶ä»–")
                desc = cat.get("description", "")
                papers = cat.get("papers", [])
                paper_nums = [str(p.get("index", "")) for p in papers]
                cat_text = f"#### {name} ({len(papers)}ç¯‡)\n"
                cat_text += f"- è®ºæ–‡ç¼–å·: `{', '.join(paper_nums)}`\n"
                if desc:
                    cat_text += f"- è¯´æ˜: {desc}\n"
                lines.append(cat_text)

        return "\n".join(lines)

    def search_papers_stream(query: str, mode: str = "auto"):
        """æµå¼æœç´¢è®ºæ–‡ - å®æ—¶æ˜¾ç¤ºè¿›åº¦"""
        if not query.strip():
            yield "è¯·è¾“å…¥ç ”ç©¶é—®é¢˜", "", "", "", ""
            return

        start_time = datetime.now()
        actual_mode = "auto" if mode == "æ™ºèƒ½åˆ¤æ–­" else ("simple" if mode == "å¿«é€Ÿæœç´¢" else "deep_research")

        # é˜¶æ®µ1: æ˜¾ç¤ºå¼€å§‹çŠ¶æ€
        start_time_str = start_time.strftime("%H:%M:%S")
        header = f"## ğŸ” æŸ¥è¯¢åˆ†æ\n\n"
        header += f"**æŸ¥è¯¢**: {query}\n\n"
        header += f"**æ¨¡å¼**: {'ğŸš€ æ·±åº¦ç ”ç©¶' if actual_mode == 'deep_research' or (actual_mode == 'auto' and len(query) > 20) else 'âš¡ å¿«é€Ÿæœç´¢'}\n\n"
        header += f"**çŠ¶æ€**: â³ æ­£åœ¨åˆ†ææŸ¥è¯¢... (å¼€å§‹äº {start_time_str})\n"

        yield header, f"â³ æ­£åœ¨åˆ†æé—®é¢˜ï¼Œè¯·ç¨å€™...\n\n> å¼€å§‹æ—¶é—´: {start_time_str}ï¼Œå¯ç‚¹å‡»ã€Œåœæ­¢ã€æŒ‰é’®å–æ¶ˆ", "", "*ğŸ”„ æœç´¢ä¸­...*", "*ğŸ”„ æœç´¢ä¸­...*"

        # é˜¶æ®µ2: æ‰§è¡Œæœç´¢
        try:
            result = assistant.process_query(query, mode=actual_mode)
        except Exception as e:
            elapsed = (datetime.now() - start_time).total_seconds()
            error_msg = f"## âŒ æœç´¢å‡ºé”™\n\nè€—æ—¶: {elapsed:.1f}ç§’\n\né”™è¯¯: {str(e)}"
            yield header.replace("â³ æ­£åœ¨åˆ†ææŸ¥è¯¢...", f"âŒ å‡ºé”™ ({elapsed:.1f}s)"), error_msg, "", "", ""
            return

        elapsed = (datetime.now() - start_time).total_seconds()

        # æ›´æ–° header
        header = f"## ğŸ” æŸ¥è¯¢åˆ†æ\n\n"
        header += f"**æ„å›¾**: {result.get('intent', 'æœªè¯†åˆ«')}\n\n"
        keywords = result.get('keywords', [])
        if keywords:
            header += f"**æœç´¢å…³é”®è¯**: `{'`, `'.join(keywords)}`\n\n"
        mode_display = "ğŸš€ æ·±åº¦ç ”ç©¶" if result['mode'] == "deep_research" else "âš¡ å¿«é€Ÿæœç´¢"
        header += f"**æ¨¡å¼**: {mode_display} | "
        header += f"**æœç´¢æº**: {', '.join(result.get('sources', [])) or 'æ— '} | "
        header += f"**æ‰¾åˆ°**: {result.get('total_found', len(result.get('papers', [])))} ç¯‡\n\n"
        header += f"**æ€»è€—æ—¶**: âœ… {elapsed:.1f}ç§’\n"

        # æ·±åº¦ç ”ç©¶æ¨¡å¼ï¼šæ˜¾ç¤ºç ”ç©¶æŠ¥å‘Š
        report_output = ""
        if result['mode'] == 'deep_research' and result.get('report'):
            # æ˜¾ç¤ºå­é—®é¢˜åˆ†è§£
            decomposition = result.get('decomposition', {})
            if decomposition:
                report_output += "## ğŸ“‹ é—®é¢˜åˆ†è§£\n\n"
                report_output += f"**é—®é¢˜ç±»å‹**: {decomposition.get('query_type', 'N/A')}\n\n"
                report_output += f"**ç ”ç©¶ç­–ç•¥**: {decomposition.get('strategy', 'N/A')}\n\n"
                sub_questions = decomposition.get('sub_questions', [])
                if sub_questions:
                    report_output += "**å­é—®é¢˜**:\n"
                    for i, sq in enumerate(sub_questions, 1):
                        report_output += f"{i}. {sq.get('question', '')} *(ç›®çš„: {sq.get('purpose', '')})*\n"
                    report_output += "\n"

            # æ˜¾ç¤ºç ”ç©¶æŠ¥å‘Š
            report_output += "---\n\n"
            report_output += result['report']

            # æ˜¾ç¤ºå…ƒæ•°æ®å’Œå„é˜¶æ®µè€—æ—¶
            metadata = result.get('metadata', {})
            if metadata:
                report_output += "\n\n---\n"
                report_output += f"**æ€»è€—æ—¶: {metadata.get('duration_seconds', 0):.1f}ç§’** | "
                report_output += f"å­é—®é¢˜: {metadata.get('sub_questions_count', 0)}ä¸ª | "
                report_output += f"è®ºæ–‡: {metadata.get('total_papers', 0)}ç¯‡\n\n"

                # æ˜¾ç¤ºå„é˜¶æ®µè€—æ—¶è¯¦æƒ…
                stage_times = metadata.get('stage_times', {})
                if stage_times:
                    report_output += "**â±ï¸ å„é˜¶æ®µè€—æ—¶:**\n"
                    for stage, time_sec in stage_times.items():
                        stage_name = stage.split('_', 1)[1] if '_' in stage else stage
                        report_output += f"- {stage_name}: {time_sec:.1f}ç§’\n"

        # é˜…è¯»å¯¼èˆªï¼ˆå¿«é€Ÿæœç´¢æ¨¡å¼ï¼‰
        reading_guide = result.get('reading_guide', {})
        guide_output = format_reading_guide(reading_guide) if result['mode'] == 'simple' else ""

        # è®ºæ–‡åˆ—è¡¨ï¼ˆæ·±åº¦ç ”ç©¶æ¨¡å¼ä½¿ç”¨åŸå§‹æœç´¢ç»“æœï¼Œç‹¬ç«‹äºæŠ¥å‘Šå¼•ç”¨ï¼‰
        if result['mode'] == 'deep_research':
            arxiv_papers = result.get('arxiv_papers', [])
            openalex_papers = result.get('openalex_papers', [])

            # arXiv è®ºæ–‡ç‹¬ç«‹ç¼–å·ä»1å¼€å§‹
            arxiv_output = f"### arXiv æœ€æ–°è®ºæ–‡ ({len(arxiv_papers)}ç¯‡)\n\n"
            arxiv_output += "> â„¹ï¸ *ä»¥ä¸‹ç¼–å·ä¸æŠ¥å‘Šå¼•ç”¨ç¼–å·æ— å…³*\n\n"
            for i, paper in enumerate(arxiv_papers, 1):
                arxiv_output += format_paper(paper, i)
            if not arxiv_papers:
                arxiv_output += "*æš‚æ— ç»“æœ*\n"

            # OpenAlex è®ºæ–‡ç‹¬ç«‹ç¼–å·ä»1å¼€å§‹
            openalex_output = f"### OpenAlex ç»å…¸è®ºæ–‡ ({len(openalex_papers)}ç¯‡)\n\n"
            openalex_output += "> â„¹ï¸ *ä»¥ä¸‹ç¼–å·ä¸æŠ¥å‘Šå¼•ç”¨ç¼–å·æ— å…³*\n\n"
            for i, paper in enumerate(openalex_papers, 1):
                openalex_output += format_paper(paper, i)
            if not openalex_papers:
                openalex_output += "*æš‚æ— ç»“æœ*\n"
        else:
            arxiv_papers = result.get('arxiv_papers', [])
            openalex_papers = result.get('openalex_papers', [])

            arxiv_output = f"### arXiv æœ€æ–°è®ºæ–‡ ({len(arxiv_papers)}ç¯‡)\n\n"
            for i, paper in enumerate(arxiv_papers, 1):
                arxiv_output += format_paper(paper, i)
            if not arxiv_papers:
                arxiv_output += "*æš‚æ— ç»“æœ*\n"

            start_index = len(arxiv_papers) + 1
            openalex_output = f"### OpenAlex ç»å…¸è®ºæ–‡ ({len(openalex_papers)}ç¯‡)\n\n"
            for i, paper in enumerate(openalex_papers, start_index):
                openalex_output += format_paper(paper, i)
            if not openalex_papers:
                openalex_output += "*æš‚æ— ç»“æœ*\n"

        yield header, report_output, guide_output, arxiv_output, openalex_output

    # åˆ›å»ºç•Œé¢
    with gr.Blocks(title="ç§‘ç ”åŠ©æ‰‹", theme=gr.themes.Soft()) as app:
        gr.Markdown(
            """
            # ğŸ”¬ ç§‘ç ”åŠ©æ‰‹ v0.3.0

            è¾“å…¥ä½ çš„ç ”ç©¶é—®é¢˜ï¼Œæˆ‘ä¼šå¸®ä½ æœç´¢ç›¸å…³è®ºæ–‡å¹¶æä¾›é˜…è¯»å»ºè®®ã€‚

            **v0.3.0 æ–°åŠŸèƒ½**:
            - ğŸš€ **æ·±åº¦ç ”ç©¶æ¨¡å¼**: å­é—®é¢˜åˆ†è§£ + å¹¶è¡Œæœç´¢ + ç ”ç©¶æŠ¥å‘Šç”Ÿæˆ
            - â±ï¸ **å®æ—¶è¿›åº¦æ˜¾ç¤º**: æ˜¾ç¤ºå„é˜¶æ®µè€—æ—¶
            - â¹ï¸ **åœæ­¢æŒ‰é’®**: å¯éšæ—¶å–æ¶ˆæœç´¢
            """
        )

        with gr.Row():
            query_input = gr.Textbox(
                label="ç ”ç©¶é—®é¢˜",
                placeholder="ä¾‹å¦‚ï¼šå¯¹æ¯” Transformer å’Œ RNN çš„ä¼˜åŠ£",
                lines=2,
                scale=3,
            )
            mode_selector = gr.Radio(
                choices=["æ™ºèƒ½åˆ¤æ–­", "å¿«é€Ÿæœç´¢", "æ·±åº¦ç ”ç©¶"],
                value="æ™ºèƒ½åˆ¤æ–­",
                label="æœç´¢æ¨¡å¼",
                scale=1,
            )

        with gr.Row():
            search_btn = gr.Button("ğŸ” æœç´¢è®ºæ–‡", variant="primary", scale=4)
            stop_btn = gr.Button("â¹ï¸ åœæ­¢", variant="stop", scale=1)

        # æŸ¥è¯¢åˆ†æåŒº
        header_output = gr.Markdown(label="æŸ¥è¯¢åˆ†æ")

        # æ·±åº¦ç ”ç©¶æŠ¥å‘ŠåŒº
        report_output = gr.Markdown(label="ç ”ç©¶æŠ¥å‘Š")

        # é˜…è¯»å¯¼èˆªåŒº
        guide_output = gr.Markdown(label="é˜…è¯»å»ºè®®")

        # åˆ†æ æ˜¾ç¤ºç»“æœ
        with gr.Row():
            with gr.Column():
                arxiv_output = gr.Markdown(label="arXivè®ºæ–‡")
            with gr.Column():
                openalex_output = gr.Markdown(label="OpenAlexè®ºæ–‡")

        # ç¤ºä¾‹
        gr.Examples(
            examples=[
                ["å¯¹æ¯” Transformer å’Œ RNN çš„ä¼˜åŠ£"],
                ["RAGåœ¨æ–‡æ¡£è§£æä»»åŠ¡ä¸­çš„ä½œç”¨"],
                ["Transformeræ³¨æ„åŠ›æœºåˆ¶"],
                ["å¤§æ¨¡å‹æœ€æ–°è¿›å±•"],
            ],
            inputs=query_input,
        )

        # æœç´¢äº‹ä»¶ï¼ˆæµå¼è¾“å‡ºï¼‰
        search_event = search_btn.click(
            fn=search_papers_stream,
            inputs=[query_input, mode_selector],
            outputs=[header_output, report_output, guide_output, arxiv_output, openalex_output]
        )
        submit_event = query_input.submit(
            fn=search_papers_stream,
            inputs=[query_input, mode_selector],
            outputs=[header_output, report_output, guide_output, arxiv_output, openalex_output]
        )

        # åœæ­¢æŒ‰é’®å–æ¶ˆæœç´¢
        stop_btn.click(
            fn=None,
            inputs=None,
            outputs=None,
            cancels=[search_event, submit_event]
        )

    return app


if __name__ == "__main__":
    app = create_app()
    app.launch(share=False)
